{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aware-adrian",
   "metadata": {},
   "source": [
    "# Importing Oddsshark.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scraping libraries, pandas, and numpy\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def extract_team_data(team_name,team_link,season='2021',n = 5):\n",
    "    #Season can go back to 2017\n",
    "    #n is the lag for the spread wins\n",
    "    \n",
    "    #From this page, extract the html\n",
    "    team_response = requests.get(team_link +'/' + str(season))\n",
    "    assert team_response.status_code == 200, '{0} returned a status code that was not 200'.format(team_links[0])\n",
    "\n",
    "    #Extract the appropriate table\n",
    "    game_logs_child = BeautifulSoup(team_response.text)\n",
    "    \n",
    "    #Capture the table and check for other tables that could disturb this process\n",
    "    table_request = game_logs_child.find_all(class_=\"table table--striped table--fixed-column\")\n",
    "    if len(table_request) != 1:\n",
    "        raise RuntimeError('The wrong table may have been captured by this request.')\n",
    "    game_table = table_request[0]\n",
    "\n",
    "    #Capture column names\n",
    "    th_objects = game_table.find_all('th')\n",
    "    columns = [th.text for th in th_objects]\n",
    "\n",
    "    #Create all rows of the data frame\n",
    "    game_table_rows = game_table.find('tbody').find_all('tr')\n",
    "    table_list = []\n",
    "    for row in game_table_rows:\n",
    "        td_list = [td.text for td in row.find_all('td')]\n",
    "        table_list.append(td_list)\n",
    "\n",
    "    #Create the pandas DataFrame\n",
    "    team_df = pd.DataFrame(table_list,columns=columns)\n",
    "\n",
    "    #Add team name as an additional column\n",
    "    team_df['Team'] = team_name\n",
    "\n",
    "    #Clean this dataframe and return\n",
    "    final_df = clean_team_df(team_df,season,n)\n",
    "    \n",
    "    #Convert team names to abbreviations for easy comparison\n",
    "    final_df = (final_df.merge(pd.read_csv('input-data/nba_abbr_map.csv').rename({'Team':'Home_Team','Abbr':'Home_Team_Abbr'},axis=1,errors='raise'),how='left',on='Home_Team')\n",
    "                .drop('Home_Team',axis=1)\n",
    "                .rename({'Home_Team_Abbr':'Home_Team'},axis=1,errors='raise'))\n",
    "    final_df = (final_df.merge(pd.read_csv('input-data/nba_abbr_map.csv').rename({'Team':'Away_Team','Abbr':'Away_Team_Abbr'},axis=1,errors='raise'),how='left',on='Away_Team')\n",
    "                .drop('Away_Team',axis=1)\n",
    "                .rename({'Away_Team_Abbr':'Away_Team'},axis=1,errors='raise'))\n",
    "\n",
    "    return final_df.set_index(['Date','Home_Team','Away_Team'])\n",
    "\n",
    "def clean_team_df(clean_team_df, season, n):\n",
    "    #Remove leading/trailing white-space in the table\n",
    "    clean_team_df = clean_team_df.rename(columns=lambda x: x.strip())\n",
    "    for column in clean_team_df:\n",
    "        clean_team_df[column] = clean_team_df[column].str.strip()\n",
    "\n",
    "    #Drop empty rows, i.e. score column contains empty string\n",
    "    clean_team_df['Score'] = clean_team_df['Score'].replace('',np.nan)\n",
    "    clean_team_df.dropna(inplace=True)\n",
    "\n",
    "    ######################\n",
    "    # Home/Away Teams\n",
    "    ######################\n",
    "    #Set Home to True/False depending on if 'vs' is the first string in 'Opponent'\n",
    "    #Then update Opponent to the correct team name (the rest of the strings in 'Opponent')\n",
    "    clean_team_df['Opponent'] = clean_team_df['Opponent'].str.split()\n",
    "    clean_team_df.loc[:,'Home'] = clean_team_df['Opponent'].map(lambda x: x[0]=='vs')\n",
    "    clean_team_df['Opponent'] = clean_team_df['Opponent'].map(lambda x: ' '.join(x[1:]) )\n",
    "\n",
    "    #Now modify the dataframe to set 'Home_Team' to 'Team' and 'Away_Team' to 'Opponent' if 'Home' is True\n",
    "    clean_team_df.loc[clean_team_df['Home'], 'Home_Team'] = clean_team_df.loc[:,'Team']\n",
    "    clean_team_df.loc[clean_team_df['Home'], 'Away_Team'] = clean_team_df.loc[:,'Opponent']\n",
    "\n",
    "    #Else if 'Home' is False, set 'Home_Team' to 'Opponent' and 'Away_Team' to 'Team'\n",
    "    clean_team_df.loc[clean_team_df['Home'] == False, 'Home_Team'] = clean_team_df.loc[:,'Opponent']\n",
    "    clean_team_df.loc[clean_team_df['Home'] == False, 'Away_Team'] = clean_team_df.loc[:,'Team']\n",
    "\n",
    "    ######################\n",
    "    # Score\n",
    "    ######################\n",
    "    #For 'Score' in the format '122-121':\n",
    "    clean_team_df['Score'] = clean_team_df['Score'].str.split('-')\n",
    "\n",
    "    #If Home == True & Result == W: Set Home Score equal to score[0], Away Score equal to score[1]\n",
    "    clean_team_df.loc[ (clean_team_df['Home']) & (clean_team_df['Result'] == 'W'),'Home_Score'] = clean_team_df['Score'].str[0]\n",
    "    clean_team_df.loc[ (clean_team_df['Home']) & (clean_team_df['Result'] == 'W'),'Away_Score'] = clean_team_df['Score'].str[1]\n",
    "\n",
    "    #if Home == True & Result == L: Set Home Score equal to score[1], Away Score equal to score[0]\n",
    "    clean_team_df.loc[ (clean_team_df['Home']) & (clean_team_df['Result'] == 'L'),'Home_Score'] = clean_team_df['Score'].str[1]\n",
    "    clean_team_df.loc[ (clean_team_df['Home']) & (clean_team_df['Result'] == 'L'),'Away_Score'] = clean_team_df['Score'].str[0]\n",
    "\n",
    "    #If Home == False & Result == W: Set Home Score equal to score[1], Away Score equal to score[0]\n",
    "    clean_team_df.loc[ (clean_team_df['Home'] == False) & (clean_team_df['Result'] == 'W'),'Home_Score'] = clean_team_df['Score'].str[1]\n",
    "    clean_team_df.loc[ (clean_team_df['Home'] == False) & (clean_team_df['Result'] == 'W'),'Away_Score'] = clean_team_df['Score'].str[0]\n",
    "\n",
    "    #if Home == False & Result == L: Set Home Score equal to score[0], Away Score equal to score[1]\n",
    "    clean_team_df.loc[ (clean_team_df['Home'] == False) & (clean_team_df['Result'] == 'L'),'Home_Score'] = clean_team_df['Score'].str[0]\n",
    "    clean_team_df.loc[ (clean_team_df['Home'] == False) & (clean_team_df['Result'] == 'L'),'Away_Score'] = clean_team_df['Score'].str[1]\n",
    "\n",
    "    #Convert Home_Score and Away Score to integers\n",
    "    clean_team_df['Home_Score'],clean_team_df['Away_Score'] = clean_team_df['Home_Score'].astype(int),clean_team_df['Away_Score'].astype(int)\n",
    "\n",
    "    ######################\n",
    "    # Spread\n",
    "    ######################\n",
    "    #If Home = True, set Home Spread to Spread \n",
    "    #If Home = False, set Away Spread to Spread\n",
    "    #Will be many NANs for every other spread value.  These should be eliminated when merging if our assumption is true.\n",
    "\n",
    "    clean_team_df.loc[ (clean_team_df['Home']), 'Home_Spread' ] = clean_team_df.loc[:,'Spread']\n",
    "    clean_team_df.loc[ (clean_team_df['Home'] == False), 'Away_Spread' ] = clean_team_df.loc[:,'Spread']\n",
    "\n",
    "    clean_team_df['Home_Spread'] = clean_team_df['Home_Spread'].astype(float)\n",
    "    clean_team_df['Away_Spread'] = clean_team_df['Away_Spread'].astype(float)\n",
    "\n",
    "    #Change the Date to a usable format to compare against other dates\n",
    "    clean_team_df['Date'] = pd.to_datetime(clean_team_df['Date'])\n",
    "\n",
    "    #\n",
    "    clean_team_df['ATS'] = clean_team_df['ATS'].mask(clean_team_df['ATS']=='W',1)\n",
    "    clean_team_df['ATS'] = clean_team_df['ATS'].mask(clean_team_df['ATS']=='P',0)\n",
    "    clean_team_df['ATS'] = clean_team_df['ATS'].mask(clean_team_df['ATS']=='L',-1)\n",
    "    \n",
    "    #Create another column for the times that this team has won against the spread in the last 'n' games, and place it into a 'home_spread_n_wins' variable or 'away_spread_n_wins' variable\n",
    "    #Change min_periods to the desired number of values before starting to show this rolling sum.  min_periods = None defaults to n periods.\n",
    "    #Convert this to a percentage of the last n games they have won ATS\n",
    "    #n = 3 as the default per the function header\n",
    "    clean_team_df['prev_ATS'] = clean_team_df['ATS'].shift(1)\n",
    "    clean_team_df['last_n_ATS'] = clean_team_df['prev_ATS'].rolling(n,min_periods=1).sum()\n",
    "    \n",
    "    #Set the Home_last_n_ATS and Away_last_n_ATS\n",
    "    clean_team_df.loc[ (clean_team_df['Home']), 'Home_last_n_ATS' ] = clean_team_df.loc[:,'last_n_ATS']\n",
    "    clean_team_df.loc[ (clean_team_df['Home']==False), 'Away_last_n_ATS' ] = clean_team_df.loc[:,'last_n_ATS']\n",
    "\n",
    "    #Set the given season year\n",
    "    clean_team_df['season'] = season\n",
    "\n",
    "    #Return this to the overall\n",
    "    final_df = clean_team_df.filter(['Date','season','Home_Team','Away_Team','Home_Score','Away_Score','Home_Spread','Away_Spread','Home_last_n_ATS','Away_last_n_ATS'],axis=1)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "animal-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#request the original oddsshark webpage\n",
    "def request_season(season):\n",
    "    #Season can be between 2017 and 2021\n",
    "\n",
    "    url = 'https://www.oddsshark.com/nba/game-logs'\n",
    "    response = requests.get(url)\n",
    "    assert response.status_code == 200, '{0} returned a status code that was not 200'.format('https://www.oddsshark.com/nba/game-logs')\n",
    "\n",
    "    #Within the id='block-system-main', extract all list items.\n",
    "    #These list items include a link for all of the resulting pages that we're looking for.\n",
    "    #Add those links to a list including the current link\n",
    "    game_logs_parent = BeautifulSoup(response.text,'lxml')\n",
    "\n",
    "    link_objects = game_logs_parent.find(id=\"block-system-main\").find_all('a')\n",
    "    team_links = ['https://www.oddsshark.com'+link.get('href') for link in link_objects]\n",
    "\n",
    "    #Also extract the (unique) team names from this page\n",
    "    team_names = [link.text for link in link_objects]\n",
    "\n",
    "    #Merge together all games\n",
    "    #Loop through all team names and links and extract the appropriate team data to get a list of dataframes for each page\n",
    "    #for name,link in zip(team_names,team_links):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for name,link in zip(team_names,team_links):\n",
    "        if len(combined_df.index) == 0:\n",
    "            combined_df = extract_team_data(name,link,season)\n",
    "        else:\n",
    "            temp_df = extract_team_data(name,link,season)\n",
    "            combined_df = combined_df.combine_first(temp_df)\n",
    "            combined_df.to_pickle('season_data/pickles/temp_season_{0}.pkl'.format(season))\n",
    "            time.sleep(.7)\n",
    "\n",
    "    combined_df.reset_index(inplace=True)\n",
    "    \n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "liberal-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Main Import\n",
    "#########################\n",
    "#Data between 2017 and 2020 will not change\n",
    "\n",
    "df_list = []\n",
    "all_seasons = [2017,2018,2019,2020,2021]\n",
    "for year in all_seasons:\n",
    "    main_scrape_df = request_season(year)\n",
    "    main_scrape_df.to_csv('season_data/nba_spreads_{0}'.format(year),index=False)\n",
    "    df_list.append(main_scrape_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
